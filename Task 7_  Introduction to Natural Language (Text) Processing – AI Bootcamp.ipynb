{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "L982FdumDCVn"
   },
   "source": [
    "# Task 7: Introduction to Natural Language (Text) Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gk9AwRFXDO6n"
   },
   "source": [
    "## Section 1: Setup and Sample Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tG2LLFb4DSrf"
   },
   "source": [
    "### **Task 1**: Import Libraries and Sample Data\n",
    "*Instruction*: Import the necessary libraries and define a sample dataset for sentiment classification."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "G6YtbgenDSWH"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this movie. It was fantastic!</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrible acting and horrible plot.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An excellent film with great characters.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Worst movie I have ever seen.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely wonderful! A must-watch.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text  label\n",
       "0      I love this movie. It was fantastic!      1\n",
       "1        Terrible acting and horrible plot.      0\n",
       "2  An excellent film with great characters.      1\n",
       "3             Worst movie I have ever seen.      0\n",
       "4       Absolutely wonderful! A must-watch.      1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "# Sample data\n",
    "data = {\n",
    "    'text': [\n",
    "        'I love this movie. It was fantastic!',\n",
    "        'Terrible acting and horrible plot.',\n",
    "        'An excellent film with great characters.',\n",
    "        'Worst movie I have ever seen.',\n",
    "        'Absolutely wonderful! A must-watch.',\n",
    "        'It was okay, nothing special.',\n",
    "        'Bad movie, waste of time.',\n",
    "        'Pretty good, I liked it.',\n",
    "        'Not great, but not terrible.',\n",
    "        'Awful! Never again.'\n",
    "    ],\n",
    "    'label': [1, 0, 1, 0, 1, 1, 0, 1, 0, 0]  # 1 = positive, 0 = negative\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03CKwCBtDzRL"
   },
   "source": [
    "## Section 2: Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oh1W_9m5DuzF"
   },
   "source": [
    "### **Task 2**: Clean the Text\n",
    "\n",
    "*Instruction*: Lowercase the text, remove punctuation, stopwords, and tokenize the sentences.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "SQTsWR6GDn6e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\lenovo\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I love this movie. It was fantastic!</td>\n",
       "      <td>love movie fantastic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Terrible acting and horrible plot.</td>\n",
       "      <td>terrible acting horrible plot</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>An excellent film with great characters.</td>\n",
       "      <td>excellent film great characters</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Worst movie I have ever seen.</td>\n",
       "      <td>worst movie ever seen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Absolutely wonderful! A must-watch.</td>\n",
       "      <td>absolutely wonderful mustwatch</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       text                          cleaned\n",
       "0      I love this movie. It was fantastic!             love movie fantastic\n",
       "1        Terrible acting and horrible plot.    terrible acting horrible plot\n",
       "2  An excellent film with great characters.  excellent film great characters\n",
       "3             Worst movie I have ever seen.            worst movie ever seen\n",
       "4       Absolutely wonderful! A must-watch.   absolutely wonderful mustwatch"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess(text):\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    tokens = word_tokenize(text)\n",
    "    filtered = [word for word in tokens if word not in stop_words]\n",
    "    return ' '.join(filtered)\n",
    "\n",
    "df['cleaned'] = df['text'].apply(preprocess)\n",
    "df[['text', 'cleaned']].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mVV1BgZvEE3a"
   },
   "source": [
    "## Section 3: Text Vectorization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "opUK7Z7LEIr4"
   },
   "source": [
    "### **Task 3**: Convert Text to Numerical Features\n",
    "\n",
    "*Instruction*: Use both Bag of Words and TF-IDF vectorization to convert the cleaned text.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "UW3FMdjQEEl3"
   },
   "outputs": [],
   "source": [
    "# Bag of Words\n",
    "cv = CountVectorizer()\n",
    "X_bow = cv.fit_transform(df['cleaned'])\n",
    "\n",
    "# TF-IDF\n",
    "tfidf = TfidfVectorizer()\n",
    "X_tfidf = tfidf.fit_transform(df['cleaned'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GNO0DPi3EpgF"
   },
   "source": [
    "## Section 4: Train a Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W74DNGaJEtdj"
   },
   "source": [
    "### **Task 4**: Sentiment Classification with Naive Bayes\n",
    "\n",
    "*Instruction*: Split the dataset, train a classifier using both feature sets, and evaluate the performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "aM8iWEAXEOmE"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[0 2]\n",
      " [0 1]]\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00         2\n",
      "           1       0.33      1.00      0.50         1\n",
      "\n",
      "    accuracy                           0.33         3\n",
      "   macro avg       0.17      0.50      0.25         3\n",
      "weighted avg       0.11      0.33      0.17         3\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lenovo\\Miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenovo\\Miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\lenovo\\Miniconda3\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_tfidf, df['label'], test_size=0.3, random_state=42)\n",
    "\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yFxPFagsE9mS"
   },
   "source": [
    "## Section 5: Mini Challenge â€“ Classify Your Own Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IZwIOzHXFD1a"
   },
   "source": [
    "### **Task 5**:  User Input Prediction\n",
    "\n",
    "*Instruction*: Write a function that allows the user to enter a text and receive a prediction from the trained model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "VpUFTR1JFDWk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Positive'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def predict_sentiment(text):\n",
    "    cleaned = preprocess(text)\n",
    "    vectorized = tfidf.transform([cleaned])\n",
    "    prediction = model.predict(vectorized)\n",
    "    return \"Positive\" if prediction[0] == 1 else \"Negative\"\n",
    "\n",
    "# Try it out\n",
    "predict_sentiment(\"The movie was so good and exciting!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyMwsrCp9iAurpgI0RcAbeRJ",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python (base - Miniconda)",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
